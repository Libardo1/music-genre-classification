{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree,NodeMixin\n",
    "from anytree.dotexport import RenderTreeGraph\n",
    "import os.path;\n",
    "import datetime;\n",
    "import time;\n",
    "import pandas;\n",
    "import numpy as np;\n",
    "import ast;\n",
    "import math;\n",
    "import sys;\n",
    "from copy import deepcopy\n",
    "import random\n",
    "LOG_DIR=\"log\";\n",
    "LOG_IMAGE=LOG_DIR+\"/image\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSVFile(file):\n",
    "    data=pandas.read_csv(file,\",\",header=0, na_values='?', skipinitialspace=True);\n",
    "    return data;\n",
    "    pass;\n",
    "def readTrainData(dataset):    \n",
    "    return dataset.ix[:,6:], dataset.ix[:,4:5].astype(int),dataset.ix[:,5:6];\n",
    "    pass;\n",
    "\n",
    "def readTestData(dataset):    \n",
    "    return dataset.ix[:,6:], dataset.ix[:,4:5].astype(int),dataset.ix[:,5:6];\n",
    "    pass;\n",
    "\n",
    "def getTimestamp():\n",
    "    ts = datetime.datetime.fromtimestamp(time.time()).strftime('%d-%m-%Y-%H:%M:%S')\n",
    "    return ts;\n",
    "\n",
    "def createDir(self,directory):\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory);\n",
    "        pass;\n",
    "\n",
    "def dropColumns(dataframe,colList):\n",
    "    for c in colList:\n",
    "        dataframe.drop([c], axis = 1, inplace = True);\n",
    "    pass;\n",
    "\n",
    "def dropRows(dataframe, rowList):\n",
    "    for r in rowList:\n",
    "        dataframe.drop((r), axis = 0, inplace = True)\n",
    "\n",
    "def printPlanerTree(root):\n",
    "    print(\"---------[Tree]----------\");\n",
    "    for pre, fill, node in RenderTree(root): \n",
    "        print(\"%s%s\" % (pre, node.name));   \n",
    "    pass;\n",
    "\n",
    "def saveTreeAsPNG(root,filename=None):\n",
    "    if(filename==None):\n",
    "        filename=\"gener_\"+getTimestamp();\n",
    "    RenderTreeGraph(root).to_picture(LOG_IMAGE+\"/\"+filename+\".png\");\n",
    "    print(\"Imaged Saved\")\n",
    "    pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DTNode(NodeMixin): # Add Node feature\n",
    "    def __init__(self, value_dic,df, feature,theta,class_count,parent=None):\n",
    "        super(DTNode, self).__init__()\n",
    "        self.parent = parent;\n",
    "        self.val=value_dic;\n",
    "        self.dataframe = df;\n",
    "        self.feature=feature;\n",
    "        self.theta = theta;  \n",
    "        self.node_height=(0 if parent==None else parent.node_height+1);\n",
    "        self.class_count=class_count;\n",
    "        self.totalrecord=sum(class_count);\n",
    "        self.isLeafNode=False;\n",
    "        self.setNodeName();\n",
    "        pass;\n",
    "    \n",
    "    def setNodeName(self):\n",
    "        if(self.feature==None and self.theta==None):\n",
    "            op=self.val[\"op\"];\n",
    "            sign=( \">\" if op==1 else \"<\" );\n",
    "            self.name = \"[\"+sign+\" \"+str(self.parent.theta)+\"] Leaf \"+str(self.class_count);\n",
    "            self.isLeafNode=True;\n",
    "        elif(self.theta==None):\n",
    "            self.name = self.feature+\" [ROOT] \"+str(self.class_count);\n",
    "            self.isLeafNode=False;\n",
    "        else:\n",
    "            self.name = self.feature+\" [Theta=\"+str(self.theta)+\"] \"+str(self.class_count);\n",
    "            self.isLeafNode=False;\n",
    "        pass;\n",
    "    \n",
    "    def setData(self,feature,theta):\n",
    "        self.feature=feature;\n",
    "        self.theta = theta;\n",
    "        self.setNodeName();\n",
    "        pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data: all continous data\n",
    "# tree: binary\n",
    "# feature repitation: allowed \n",
    "class DecisionTree():\n",
    "    \n",
    "    dataframe=None;\n",
    "    no_of_class=10;#number of features 0 to k-1\n",
    "    operator={\"less\":-1,\"equal\":0,\"greater\":1};\n",
    "    output_col=None;\n",
    "    features=None;\n",
    "    visited_feature=None;\n",
    "    repetition_allowed=True\n",
    "    minus_infinity=-9999;\n",
    "    detail_log_enabled=True;\n",
    "    logging_enabled=True;\n",
    "    min_record_count=2;\n",
    "    root_node=None;\n",
    "    max_depth=10;\n",
    "    #-----------------------------------------\n",
    "    \n",
    "    def __init__(self,df,output_col):\n",
    "        self.dataframe=df;\n",
    "        self.output_col=output_col;\n",
    "        self.features=list(self.dataframe.columns);\n",
    "        self.features.remove(self.output_col);\n",
    "        self.no_of_features=len(self.features);\n",
    "        self.visited_feature=[];\n",
    "        \n",
    "    #assuming all data is continous\n",
    "    def splitDataset(self,df,feature,value_dic):\n",
    "        val=value_dic[\"val\"];\n",
    "        op=value_dic[\"op\"];        \n",
    "        subsetdf=None;\n",
    "        if(op==self.operator[\"equal\"]):\n",
    "            print(\"Error: Equal not supported\");\n",
    "            subsetdf=None;# no categorical data: Assumption        \n",
    "        elif(op==self.operator[\"less\"]):\n",
    "            subsetdf= df.loc[(df[feature]<=val)];\n",
    "            \n",
    "        elif(op==self.operator[\"greater\"]):\n",
    "            subsetdf= df.loc[(df[feature]>val)];            \n",
    "        \n",
    "        return subsetdf;\n",
    "    \n",
    "    #entropy function\n",
    "    def getEntropy(self,pci):\n",
    "        ent=-1*pci*math.log(pci,2);\n",
    "        return ent;\n",
    "    \n",
    "    #impurity function\n",
    "    def getImpurity(self,pci):        \n",
    "        imp=self.getEntropy(pci);\n",
    "        return imp;\n",
    "    \n",
    "    #Pr(c=i)= (# of c=i)/total\n",
    "    def getPci(self,df,ci):\n",
    "        p=0.0;#probablity\n",
    "        y=df[self.output_col];\n",
    "        total=len(y);\n",
    "        no_of_ci=(y==ci).sum();\n",
    "        if(no_of_ci!=0 and total!=0):\n",
    "            p=float(no_of_ci)/total;\n",
    "        return p;\n",
    "        pass;\n",
    "    \n",
    "    def getClassCount(self,df):\n",
    "        y=df[self.output_col];\n",
    "        count=np.zeros(self.no_of_class);\n",
    "        for ci in range(self.no_of_class):\n",
    "            count[ci]=(y==ci).sum();\n",
    "        return count.astype(int);\n",
    "            \n",
    "    #return sum of impurity for all classes\n",
    "    def getNetImpurity(self,df):\n",
    "        e=0;\n",
    "        for i in range(self.no_of_class):\n",
    "            pci=self.getPci(df,i);       \n",
    "            if(pci!=0):\n",
    "                e+=self.getImpurity(pci);            \n",
    "        return e;\n",
    "        pass;\n",
    "    \n",
    "    #feature is continous\n",
    "    def getFeatureVal(self,df,feature):\n",
    "        mean=df[feature].mean();\n",
    "        values=[{\"val\":mean,\"op\":self.operator[\"less\"]},{\"val\":mean,\"op\":self.operator[\"greater\"]}];\n",
    "        return values,mean;\n",
    "        pass;\n",
    "    \n",
    "    #find gain for the given feature\n",
    "    def getGain(self,df,feature):\n",
    "        #H(S)\n",
    "        imp_S=self.getNetImpurity(df);\n",
    "        values,theta=self.getFeatureVal(df,feature);\n",
    "        net_Sf=0;\n",
    "        total_row=df[feature].count();        \n",
    "        for val_dic in values:\n",
    "            self.detaillog(\"------[GAIN: \"+feature+\"]------------\")  \n",
    "            self.detaillog(\"df record count:\",self.getDFRecordCount(df));\n",
    "            self.detaillog(\"val:\",val_dic);                        \n",
    "            Sv=self.splitDataset(df,feature,val_dic);                        \n",
    "            self.detaillog(\"df record count:\",self.getDFRecordCount(Sv));\n",
    "            len_Sv=Sv[feature].count();\n",
    "            self.detaillog(\"len:\",len_Sv);                        \n",
    "            ratio=float(len_Sv)/total_row;                        \n",
    "            self.detaillog(\"ratio:\",ratio);            \n",
    "            imp_Sv=self.getNetImpurity(Sv);\n",
    "            self.detaillog(\"imp_sv:\",imp_Sv);             \n",
    "            net_Sf+=(ratio*imp_Sv); \n",
    "            self.detaillog(\"net_sf:\",net_Sf)\n",
    "        if(self.detail_log_enabled):\n",
    "            print(\"imp_s:\",imp_S,\" net_sv:\",net_Sf,\"  diff:\",imp_S-net_Sf)\n",
    "        gain=float(imp_S-net_Sf);        \n",
    "        return gain;    \n",
    "        pass;\n",
    "    \n",
    "    #Finds the best feature among all feature\n",
    "    #select my maximum gain\n",
    "    def getBestFeature(self,df):\n",
    "        \n",
    "        gain_list=np.zeros(self.no_of_features);\n",
    "        for i in range(self.no_of_features):\n",
    "            f=self.features[i];\n",
    "            self.detaillog(\"---->\",f);\n",
    "            if(self.repetition_allowed or (self.repetition_allowed==False and f not in visited_features)):\n",
    "                g=self.getGain(df,f);               \n",
    "            else:\n",
    "                g=self.minus_infinity;\n",
    "            gain_list[i]=g;\n",
    "            self.log(\"Gain_\"+self.features[i]+\":\",g);\n",
    "            \n",
    "        index=gain_list.argmax();  \n",
    "        feature=self.features[index];        \n",
    "        return feature;\n",
    "        pass;\n",
    "\n",
    "    \n",
    "    def attachChildNodes(self,parent_node,df,feature,values):\n",
    "        for val in values:\n",
    "            subdf=self.splitDataset(df,feature,val);  \n",
    "            #if feature of the node is not decided i.e None then its a leave node.\n",
    "            newnode=DTNode(val,subdf,None,None,self.getClassCount(subdf),parent_node);        \n",
    "    \n",
    "    #This will generate the Tree\n",
    "    def generateTree(self,dtnode):     \n",
    "        self.log(\"node height:\",dtnode.node_height);\n",
    "        if(dtnode.node_height>self.max_depth):\n",
    "            return;#donot do anything        \n",
    "        if(dtnode.totalrecord>=self.min_record_count):\n",
    "            df=dtnode.dataframe;\n",
    "            \n",
    "            best_feature=self.getBestFeature(df);\n",
    "            self.detaillog(\"###Best Feature:\",best_feature);\n",
    "            values,theta=self.getFeatureVal(df,best_feature);\n",
    "            dtnode.setData(best_feature,theta);\n",
    "            self.attachChildNodes(dtnode,df,best_feature,values);\n",
    "            \n",
    "            for child in dtnode.children:                \n",
    "                self.generateTree(child);\n",
    "            \n",
    "        pass;\n",
    "    \n",
    "        pass;\n",
    "    def createDecisionTree(self):  \n",
    "        best_feature=self.getBestFeature(df);\n",
    "        self.detaillog(\"###Best Feature:\",best_feature);\n",
    "        values,theta=self.getFeatureVal(df,best_feature);\n",
    "        root_node=DTNode(None,self.dataframe,best_feature,theta,self.getClassCount(df));\n",
    "        self.attachChildNodes(root_node,df,best_feature,values);  \n",
    "        self.log(\"node height:\",root_node.node_height);\n",
    "        for child in root_node.children:                \n",
    "            self.generateTree(child);\n",
    "        self.root_node=root_node;\n",
    "        return root_node;    \n",
    "        pass;\n",
    "    \n",
    "    #predicits the value of the class\n",
    "    def predictProbilityPerClass(self,p_input):\n",
    "        node=self.root_node;\n",
    "        while(node.isLeafNode==False):\n",
    "            val=p_input[node.feature];\n",
    "            #binary tree.left branch < theta and right is >\n",
    "            node= ( node.children[0] if(val<=node.theta) else node.children[1] )\n",
    "        \n",
    "        self.detaillog(\"class\",node.class_count);\n",
    "        prob=np.array(node.class_count).astype(float)/node.totalrecord;\n",
    "        self.detaillog(\"probabiliy:\",prob);\n",
    "        return prob;\n",
    "        pass;\n",
    "    \n",
    "    def predictClass(self,p_input):\n",
    "            prob=self.predictProbilityPerClass(p_input);\n",
    "            y=prob.argmax();\n",
    "            return y;\n",
    "        \n",
    "    #return no. of record in data frame    \n",
    "    def getDFRecordCount(self,df):\n",
    "        return df.count(axis=0)[0];\n",
    "    \n",
    "    def predictForDF(self,df):\n",
    "        rcount=self.getDFRecordCount(df);\n",
    "        y_list=[];\n",
    "        for i in range(rcount):\n",
    "            r=df.iloc[i];\n",
    "            y=self.predictClass(r);\n",
    "            y_list.append(y);\n",
    "        return y_list;\n",
    "    \n",
    "    #find error in prediction\n",
    "    def findError(self,y_pred,y_act):\n",
    "        size=len(y_act);\n",
    "        misclassifedPoints = (y_pred != y_act).sum()  ;\n",
    "        accuracy = (float(size - misclassifedPoints)*100) / size;\n",
    "        return misclassifedPoints,accuracy;\n",
    "        pass;\n",
    "    \n",
    "    def log(self,text,data=None):\n",
    "        if self.logging_enabled:\n",
    "            if(data!=None):\n",
    "                print(text,data);\n",
    "            else:\n",
    "                print(text);\n",
    "    def detaillog(self,text,data=None):\n",
    "        if self.detail_log_enabled:\n",
    "            if(data!=None):\n",
    "                print(text,data);\n",
    "            else:\n",
    "                print(text);\n",
    "        pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A    B    C    D\n",
      "0  1    2   30    4\n",
      "1  2    6   70    8\n",
      "2  2  208  101   12\n",
      "3  3  198  150  160\n",
      "-------------------\n",
      "Gain_B: 0.5\n",
      "Gain_C: 0.5\n",
      "Gain_D: 0.8112781244591328\n",
      "node height: 0\n",
      "node height: 1\n",
      "Gain_B: 0.2516291673878229\n",
      "Gain_C: 0.9182958340544896\n",
      "Gain_D: 0.2516291673878229\n",
      "node height: 2\n",
      "node height: 2\n",
      "node height: 1\n",
      "---------[Tree]----------\n",
      "D [Theta=46.0] [0 1 2 1 0 0 0 0 0 0]\n",
      "├── C [Theta=67.0] [0 1 2 0 0 0 0 0 0 0]\n",
      "│   ├── [< 67.0] Leaf [0 1 0 0 0 0 0 0 0 0]\n",
      "│   └── [> 67.0] Leaf [0 0 2 0 0 0 0 0 0 0]\n",
      "└── [> 46.0] Leaf [0 0 0 1 0 0 0 0 0 0]\n",
      "y: [1, 2, 2, 3]\n",
      "misclassifed: 0  accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "#TEST DATA\n",
    "arr=np.array([[1,2,30,4],[2,6,70,8],[2,208,101,12],[3,198,150,160]])\n",
    "df = pandas.DataFrame(arr, columns=['A', 'B', 'C', 'D'])\n",
    "print(df)\n",
    "print(\"-------------------\");\n",
    "dt=DecisionTree(df,'A');\n",
    "dt.min_record_count=2;\n",
    "dt.max_depth=1;\n",
    "dt.detail_log_enabled=False;\n",
    "root=dt.createDecisionTree();\n",
    "printPlanerTree(root);\n",
    "#saveTreeAsPNG(root);\n",
    "\n",
    "y_pred=dt.predictForDF(df)\n",
    "print(\"y:\",y_pred);\n",
    "m,a=dt.findError(y_pred,np.array(df['A']))\n",
    "print(\"misclassifed:\",m,\" accuracy:\",a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (801, 20) test (200, 20)\n",
      "Index(['y_index', 'centroid mean', 'centroid var', 'rolloff mean',\n",
      "       'rolloff var', 'zero mean', 'zero var', 'rms mean', 'rms var',\n",
      "       'contrast mean', 'contrast var', 'mfcc1 mean', 'mfcc1 var',\n",
      "       'mfcc2 mean', 'mfcc2 var', 'mfcc3 mean', 'mfcc3 var', 'mfcc4 mean',\n",
      "       'mfcc4 var', 'mfcc5 mean', 'mfcc5 var'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Music GENER CLASSIFICATION.....\n",
    "dir=\"data/\"\n",
    "trainFile=dir+\"train.csv\";\n",
    "testFile=dir+\"test.csv\";\n",
    "trained_dataset=readCSVFile(trainFile);\n",
    "test_dataset=readCSVFile(testFile);\n",
    "trained_data,trained_y,trained_y_vector=readTrainData(trained_dataset);\n",
    "test_data,test_y,test_y_vector=readTestData(test_dataset);\n",
    "\n",
    "mtx_train =trained_data.as_matrix(columns=None)\n",
    "mtx_train_y  =trained_y.as_matrix(columns=None)\n",
    "mtx_train_y=np.array(list((e[0] for e in mtx_train_y)));\n",
    "\n",
    "mtx_test=test_data.as_matrix(columns=None);\n",
    "mtx_test_y=test_y.as_matrix(columns=None);\n",
    "mtx_test_y=np.array(list((e[0] for e in mtx_test_y)));\n",
    "#print(\"train\",np.shape(mtx_train),\"test\",np.shape(mtx_test));\n",
    "#Note: mtx_*** no in use\n",
    "#----------------------------------------------||||\n",
    "colList=[\"Unnamed: 0\",\"Unnamed: 0.1\",\"id\",\"type\",\"y\"];\n",
    "dropColumns(trained_dataset,colList);\n",
    "dropColumns(test_dataset,colList);\n",
    "\n",
    "#Note: Data frame in use 'trained_dataset' and 'test_dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 17) (200, 17)\n",
      "training Started\n",
      "Train Data: misclassifed: 228  accuracy: 60.416666666666664\n",
      "Test Data: misclassifed: 105  accuracy: 47.5\n",
      "(291, 7) (200, 7)\n",
      "training Started\n",
      "Train Data: misclassifed: 157  accuracy: 46.04810996563574\n",
      "Test Data: misclassifed: 138  accuracy: 31.0\n",
      "(329, 3) (200, 3)\n",
      "training Started\n",
      "Train Data: misclassifed: 206  accuracy: 37.38601823708207\n",
      "Test Data: misclassifed: 138  accuracy: 31.0\n",
      "(300, 16) (200, 16)\n",
      "training Started\n",
      "Train Data: misclassifed: 135  accuracy: 55.0\n",
      "Test Data: misclassifed: 121  accuracy: 39.5\n",
      "(323, 15) (200, 15)\n",
      "training Started\n",
      "Train Data: misclassifed: 146  accuracy: 54.79876160990712\n",
      "Test Data: misclassifed: 111  accuracy: 44.5\n",
      "(111, 7) (200, 7)\n",
      "training Started\n",
      "Train Data: misclassifed: 62  accuracy: 44.14414414414414\n",
      "Test Data: misclassifed: 138  accuracy: 31.0\n",
      "(135, 14) (200, 14)\n",
      "training Started\n",
      "Train Data: misclassifed: 76  accuracy: 43.7037037037037\n",
      "Test Data: misclassifed: 136  accuracy: 32.0\n",
      "(171, 18) (200, 18)\n",
      "training Started\n",
      "Train Data: misclassifed: 88  accuracy: 48.538011695906434\n",
      "Test Data: misclassifed: 116  accuracy: 42.0\n",
      "(251, 7) (200, 7)\n",
      "training Started\n",
      "Train Data: misclassifed: 132  accuracy: 47.41035856573705\n",
      "Test Data: misclassifed: 125  accuracy: 37.5\n",
      "(304, 3) (200, 3)\n",
      "training Started\n",
      "Train Data: misclassifed: 187  accuracy: 38.48684210526316\n",
      "Test Data: misclassifed: 145  accuracy: 27.5\n",
      "(174, 4) (200, 4)\n",
      "training Started\n",
      "Train Data: misclassifed: 104  accuracy: 40.229885057471265\n",
      "Test Data: misclassifed: 142  accuracy: 29.0\n",
      "(559, 15) (200, 15)\n",
      "training Started\n",
      "Train Data: misclassifed: 222  accuracy: 60.28622540250447\n",
      "Test Data: misclassifed: 105  accuracy: 47.5\n",
      "(61, 7) (200, 7)\n",
      "training Started\n",
      "Train Data: misclassifed: 39  accuracy: 36.0655737704918\n",
      "Test Data: misclassifed: 145  accuracy: 27.5\n",
      "(111, 10) (200, 10)\n",
      "training Started\n",
      "Train Data: misclassifed: 66  accuracy: 40.54054054054054\n",
      "Test Data: misclassifed: 139  accuracy: 30.5\n",
      "(362, 14) (200, 14)\n",
      "training Started\n",
      "Train Data: misclassifed: 171  accuracy: 52.76243093922652\n",
      "Test Data: misclassifed: 113  accuracy: 43.5\n",
      "(366, 15) (200, 15)\n",
      "training Started\n",
      "Train Data: misclassifed: 165  accuracy: 54.91803278688525\n",
      "Test Data: misclassifed: 130  accuracy: 35.0\n",
      "(445, 3) (200, 3)\n",
      "training Started\n",
      "Train Data: misclassifed: 303  accuracy: 31.910112359550563\n",
      "Test Data: misclassifed: 160  accuracy: 20.0\n",
      "(77, 10) (200, 10)\n",
      "training Started\n",
      "Train Data: misclassifed: 40  accuracy: 48.05194805194805\n",
      "Test Data: misclassifed: 135  accuracy: 32.5\n",
      "(51, 18) (200, 18)\n",
      "training Started\n",
      "Train Data: misclassifed: 33  accuracy: 35.294117647058826\n",
      "Test Data: misclassifed: 150  accuracy: 25.0\n",
      "(272, 1) (200, 1)\n",
      "training Started\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c31b411b387a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_enabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;31m# Print status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training Started\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m#printPlanerTree(root);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#saveTreeAsPNG(root);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ba2c69c8e89a>\u001b[0m in \u001b[0;36mcreateDecisionTree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreateDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mbest_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetBestFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetaillog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"###Best Feature:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFeatureVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ba2c69c8e89a>\u001b[0m in \u001b[0;36mgetBestFeature\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gain_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgain_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    new_trained_dataset = deepcopy(trained_dataset)\n",
    "    #new_trained_dataset.columns = range(0, new_trained_dataset.shape[1])\n",
    "    new_test_dataset = deepcopy(test_dataset)\n",
    "    #new_test_dataset.columns = range(0, new_test_dataset.shape[1])\n",
    "\n",
    "    size = 0\n",
    "    while size < 200:\n",
    "        size = int(trained_dataset.shape[0] * np.random.rand())\n",
    "    rowList = np.array(random.sample(range(0, trained_dataset.shape[0]), size))\n",
    "    dropRows(new_trained_dataset, rowList)\n",
    "    size = 0\n",
    "    while size < 3:\n",
    "        size = int(trained_dataset.shape[1] * np.random.rand())\n",
    "    colList = [trained_dataset.columns[i] for i in np.array(random.sample(range(1, trained_dataset.shape[1]), size))]\n",
    "    dropColumns(new_trained_dataset, colList)\n",
    "    dropColumns(new_test_dataset, colList)\n",
    "\n",
    "\n",
    "    print(new_trained_dataset.shape, new_test_dataset.shape)\n",
    "\n",
    "    df=new_trained_dataset;\n",
    "    dt=DecisionTree(df, 'y_index');\n",
    "    dt.min_record_count=20;\n",
    "    dt.max_depth=10;\n",
    "    dt.detail_log_enabled=False; # Print status\n",
    "    dt.logging_enabled=False;# Print status\n",
    "    print(\"training Started\");\n",
    "    root=dt.createDecisionTree();\n",
    "    #printPlanerTree(root);\n",
    "    #saveTreeAsPNG(root);\n",
    "\n",
    "    y_pred=dt.predictForDF(df)\n",
    "    #print(\"y:\",y_pred);\n",
    "    m,a=dt.findError(y_pred,np.array(df['y_index']))\n",
    "    print(\"Train Data:\",\"misclassifed:\",m,\" accuracy:\",a);\n",
    "\n",
    "    df=new_test_dataset\n",
    "    y_pred=dt.predictForDF(df)\n",
    "    #print(\"y:\",y_pred);\n",
    "    m,a=dt.findError(y_pred,np.array(df['y_index']))\n",
    "    print(\"Test Data:\",\"misclassifed:\",m,\" accuracy:\",a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
