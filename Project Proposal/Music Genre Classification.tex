\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}

\begin{document}

\begin{titlepage}
\begin{center}
\vspace*{1cm}

\huge{\textbf{Music Genre Classification}}

\vspace{0.5cm}
CS725 Project

\vspace{3.5cm}
Indian Institute of Technology, Bombay\\
Department of Computer Science and Engineering
\vspace{3.5cm}

\Large{Anshul Gupta (16305R001) \\ Khursheed Ali (163059009) \\ Abhijeet Dubey (16305R006) \\ Nithin S (16305R007)}

\vfill

\vspace{0.8cm}

\includegraphics[scale=0.35]{IITB.png}
\end{center}
\end{titlepage}
 
\section{Project Description}
Sometimes it happens that we listen to a particular music, we instantly develop an affinity towards to that genre and want to listen to same type of music. Or sometimes we just want to organize our music collection based on genre.
This project aims to classify music into different categories such as:
\begin{enumerate}
 \item Rock
 \item Hip Hop
 \item Jazz
 \item Metal
 \item Classical
 \item Pop
 \item Disco
\end{enumerate}


\section{Tentative Approach}
We'll proceed using the following workflow:
\begin{itemize}
 \item Pre-process of the audio files.
 \item Extract relevant features from the pre-processed files. For example, Mel-Frequency Cepstral Coefficient, Spectral Centroid etc.
 \item Use ensemble learning for classification of the features. Classification algorithms like K-NN, Random Forest, Linear Kernel SVN etc. will be a part of our ensemble learning.
\end{itemize}


\section{Papers}
\begin{itemize}
 \item A Comparative Study on Content-based Music Genre Classification \cite{Li:2003:CSC:860435.860487}
 \item Deep Content-based Music Recommendation \cite{Oord:2013:DCM:2999792.2999907}
 \item A Benchmark Dataset for Audio Classification and Clustering \cite{HomburgEtAl_2005_ABencDataFor}
\end{itemize}

\section{Datasets}
%We will be using MSD \cite{Bertin-Mahieux2011} (Million Song Dataset). The dataset consists of almost all the information available through The Echo Nest API for one million popular tracks. This encompasses both metadata and audio analysis features. Each file is for one track which corresponds to one song, one release and one artist. All the information about these four items (track, song, release, artist) are in every file (which involves some redundancy, although the bulk of the data, relating to the audio analysis, is unique). Each audio is a 30 second sample.
We will use \textit{GTZAN Genre Collection} \cite{GTZAN}.
The dataset consists of 1000 audio tracks each 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22050Hz Mono 16-bit audio files in .wav format.


\bibliographystyle{unsrt}
\bibliography{References}


\end{document}
